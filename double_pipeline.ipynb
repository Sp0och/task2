{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Classification into 4 classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea is to use CWT images of the data and perform classification using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "- Can't drop nans collectively because of different signal lengths\n",
    "- For the imbalanced datasets we can introduce some bias towards the under-represented values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 08:23:49.982736: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from biosppy.signals import ecg\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import â€“ takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import X_train.csv dataset into a pandas dataframe\n",
    "X_train = pd.read_csv(\"X_train.csv\", index_col=\"id\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", index_col=\"id\")\n",
    "X_test = pd.read_csv(\"X_test.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.164318\n",
      "16322\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_train.loc[0].dropna().to_numpy(dtype=\"float32\")))\n",
    "print(X_train.loc[0].dropna().to_numpy(dtype=\"float32\").shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get class representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3030\n",
      "443\n",
      "1474\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "y_train_np = y_train.to_numpy()\n",
    "ones = np.where(y_train_np == 0)[0]\n",
    "twos = np.where(y_train_np == 1)[0]\n",
    "threes = np.where(y_train_np == 2)[0]\n",
    "fours = np.where(y_train_np == 3)[0]\n",
    "print(len(ones))\n",
    "print(len(twos))\n",
    "print(len(threes))\n",
    "print(len(fours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Wavelet transform:\n",
    "### Create CWT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widths = np.arange(1,31)\n",
    "# print(\"cwtmatrix shape (30 from width x # signal length\")\n",
    "# Class = 3\n",
    "# for i in range(len(threes)):\n",
    "#         print(i)\n",
    "#         # print(len(X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\")))\n",
    "#         cwtmatr = signal.cwt(X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\"), signal.ricker, widths)\n",
    "#         # print(cwtmatr.shape)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(cwtmatr, extent=[-1, 1, 31, 1], cmap='PRGn', aspect='auto',\n",
    "#                 vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())\n",
    "#         plt.axis('off')\n",
    "#         # plt.show()\n",
    "#         plt.savefig(\"3/cwtmatr_class{}_index{}.png\".format(Class, i), bbox_inches='tight', pad_inches=0)\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 334\n",
    "IMG_HEIGHT = 217\n",
    "def load_image(img, training):\n",
    "    '''Helper Function to load the image'''\n",
    "    img = tf.image.decode_png(tf.io.read_file(img), channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = img / 127.5 - 1\n",
    "    img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    if training:\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 16:42:48.104928: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "image_1 = load_image(\"3/cwtmatr_class3_index0.png\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: \n",
    "- Extract features from heartbeat templates and concatenate with scalar output from model\n",
    "- consider imbalanced dataset => add bias towards under-represented classes\n",
    "- train model\n",
    "- predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: \n",
    "<!-- per signal it plots both a few possible templates as well as the average over 180 templates -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecg_output = ecg.ecg(X_train.loc[ones[0]].dropna().to_numpy(dtype=\"float32\"))\n",
    "# print(\"classes: \", ecg_output[0].keys())\n",
    "# print(\"shape of time series: \", ecg_output[0][0].shape)\n",
    "# print(\"shape of filtered series: \", ecg_output[0][1].shape)\n",
    "# print(\"number of peaks\", ecg_output[0][2].shape[0])\n",
    "# print(\"shape of templates: \", ecg_output[0][3].shape)\n",
    "# print(\"peaks: \", ecg_output[0][2]/300)\n",
    "# print(\"templates: \", ecg_output[0][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Heartbeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(signal):\n",
    "    r_peaks = ecg.engzee_segmenter(signal, 300)['rpeaks']\n",
    "    if len(r_peaks) >= 2:\n",
    "        beats = ecg.extract_heartbeats(signal, r_peaks, 300)['templates']\n",
    "        # print(\"Beats (peaks - 1, 180 proposals of heartbeats): \", beats)\n",
    "        if len(beats) != 0:\n",
    "            mu = np.mean(beats, axis=0) \n",
    "            var = np.std(beats, axis=0)\n",
    "            md = np.median(beats, axis=0)\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.subplot(211)\n",
    "\n",
    "            ax1 = plt.subplot(211)\n",
    "            ax1.plot(beats[0,:])\n",
    "            ax1.plot(beats[1,:])\n",
    "            ax1.plot(beats[2,:])\n",
    "            ax1.plot(beats[3,:])\n",
    "            ax1.set_title(\"template samples\")\n",
    "\n",
    "            ax2 = plt.subplot(212)\n",
    "            ax2.set_title(\"average template\")\n",
    "            ax2.plot(range(mu.shape[0]), mu, label='Average HeartBeat')\n",
    "            # Fill the variance range\n",
    "            ax2.fill_between(range(mu.shape[0]), mu - var, mu + var, linewidth=0, alpha=0.1)\n",
    "            # Plot a median\n",
    "            ax2.plot(range(md.shape[0]), md,  label='Median HeartBeat', color='#CC4F1B')\n",
    "    # ecg_results = ecg.ecg(signal, sampling_rate=300, show=True)\n",
    "    # return ecg_results\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract peaks and save as concatenates matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_peaks = 159\n",
    "peaks = np.zeros((max_num_peaks, threes.shape[0]))\n",
    "for i in range(threes.shape[0]):\n",
    "    data = X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\")\n",
    "    ECG = ecg.ecg(data, sampling_rate=300, show=False)\n",
    "    ecg_dimension = ECG[2].shape[0]\n",
    "    buffer = np.zeros((max_num_peaks - ecg_dimension))\n",
    "    peaks[:,i] = np.concatenate((ECG[2], buffer), axis=0)\n",
    "np.savetxt(\"peaks/3/ecg_peaks.csv\", peaks, delimiter=\",\", fmt='%0.0f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = pd.read_csv(\"peaks/4/ecg_peaks.csv\", header=None).to_numpy(dtype=\"float32\")\n",
    "zeros = np.where(peaks == 0)\n",
    "mean = np.mean(peaks, axis=0)\n",
    "std = np.std(peaks, axis=0)\n",
    "peaks_normalized = (peaks - mean) / std\n",
    "np.savetxt(\"peaks/4/ecg_peaks_normalized.csv\", peaks_normalized, delimiter=\",\", fmt='%0.7f')\n",
    "peaks_normalized[zeros] = 0\n",
    "np.savetxt(\"peaks/4/ecg_peaks_normalized_zeros.csv\", peaks_normalized, delimiter=\",\", fmt='%0.7f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper NN Structure:\n",
    "Automatic ECG Classification Using Continuous Wavelet\n",
    "Transform and Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Paper NN structure](Paper_pipeline.png \"Paper NN Structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- insert image -->\n",
    "![Paper NN structure](Paper_NN_structure.png \"Paper NN Structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor_model():\n",
    "    '''Create feature extractor'''\n",
    "    #determine input shape\n",
    "    image_input = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    encoder = tf.keras.Sequential()\n",
    "    encoder.add(keras.layers.Conv2D(filters=16,kernel_size=7,strides=1,input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
    "    encoder.add(keras.layers.BatchNormalization())\n",
    "    encoder.add(keras.layers.ReLU())\n",
    "    encoder.add(keras.layers.MaxPool2D(5,5))\n",
    "    \n",
    "    encoder.add(keras.layers.Conv2D(32,3,1))\n",
    "    encoder.add(keras.layers.BatchNormalization())\n",
    "    encoder.add(keras.layers.ReLU())\n",
    "    encoder.add(keras.layers.MaxPool2D(3,3))\n",
    "\n",
    "    encoder.add(keras.layers.Conv2D(64,3,1))\n",
    "    encoder.add(keras.layers.BatchNormalization())\n",
    "    encoder.add(keras.layers.ReLU())\n",
    "    encoder.add(keras.layers.MaxPool2D(3))\n",
    "\n",
    "    # fully connected layer for scalar output\n",
    "    encoder.add(keras.layers.Flatten())\n",
    "    encoder.add(keras.layers.Dense(64, activation='relu'))\n",
    "    image_encoder = keras.Model(image_input, encoder(image_input))\n",
    "    # peaks encoder\n",
    "    peak_encoder = keras.Input(shape=(159))\n",
    "\n",
    "    complete_encoder = keras.layers.concatenate([image_encoder.output, peak_encoder])\n",
    "    classifier = keras.layers.Dense(32, activation='relu')(complete_encoder)\n",
    "    classifier = keras.layers.Dense(4, activation='softmax')(classifier)\n",
    "    model = keras.Model([image_encoder.input, peak_encoder], classifier)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_feature_extractor_model()\n",
    "print(model.output_shape)\n",
    "model.summary()\n",
    "# plot model\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for imbalanced dataset:\n",
    " Idea for imbalanced data: sample all classes to be of size 170 and proceed using ensemble method of the models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
