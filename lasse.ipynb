{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Classification into 4 classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea is to use CWT images of the data and perform classification using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "- Can't drop nans collectively because of different signal lengths\n",
    "- For the imbalanced datasets we can introduce some bias towards the under-represented values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from biosppy.signals import ecg\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import â€“ takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import X_train.csv dataset into a pandas dataframe\n",
    "X_train = pd.read_csv(\"X_train.csv\", index_col=\"id\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", index_col=\"id\")\n",
    "X_test = pd.read_csv(\"X_test.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.164318\n",
      "16322\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_train.loc[0].dropna().to_numpy(dtype=\"float32\")))\n",
    "print(X_train.loc[0].dropna().to_numpy(dtype=\"float32\").shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get class representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3030\n",
      "443\n",
      "1474\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "y_train_np = y_train.to_numpy()\n",
    "ones = np.where(y_train_np == 0)[0]\n",
    "twos = np.where(y_train_np == 1)[0]\n",
    "threes = np.where(y_train_np == 2)[0]\n",
    "fours = np.where(y_train_np == 3)[0]\n",
    "print(len(ones))\n",
    "print(len(twos))\n",
    "print(len(threes))\n",
    "print(len(fours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double plot function: \n",
    "per signal it plots both a few possible templates as well as the average over 180 templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_features(signal):\n",
    "#     r_peaks = ecg.engzee_segmenter(signal, 300)['rpeaks']\n",
    "#     if len(r_peaks) >= 2:\n",
    "#         beats = ecg.extract_heartbeats(signal, r_peaks, 300)['templates']\n",
    "#         # print(\"Beats (peaks - 1, 180 proposals of heartbeats): \", beats)\n",
    "#         if len(beats) != 0:\n",
    "#             # for i in range(5):\n",
    "#             #     plt.plot(beats[i])\n",
    "#             #     plt.show()\n",
    "#             mu = np.mean(beats, axis=0) \n",
    "#             var = np.std(beats, axis=0)\n",
    "#             md = np.median(beats, axis=0)\n",
    "            \n",
    "#             fig = plt.figure()\n",
    "#             plt.subplot(211)\n",
    "\n",
    "#             ax1 = plt.subplot(211)\n",
    "#             ax1.plot(beats[0,:])\n",
    "#             ax1.plot(beats[1,:])\n",
    "#             ax1.plot(beats[2,:])\n",
    "#             ax1.plot(beats[3,:])\n",
    "#             ax1.set_title(\"template samples\")\n",
    "\n",
    "#             ax2 = plt.subplot(212)\n",
    "#             ax2.set_title(\"average template\")\n",
    "#             ax2.plot(range(mu.shape[0]), mu, label='Average HeartBeat')\n",
    "#             # Fill the variance range\n",
    "#             ax2.fill_between(range(mu.shape[0]), mu - var, mu + var, linewidth=0, alpha=0.1)\n",
    "#             # Plot a median\n",
    "#             ax2.plot(range(md.shape[0]), md,  label='Median HeartBeat', color='#CC4F1B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     # plot_features(X_train.loc[ones[i]].dropna().to_numpy(dtype=\"float32\"))\n",
    "#     # plot_features(X_train.loc[twos[i]].dropna().to_numpy(dtype=\"float32\"))\n",
    "#     # plot_features(X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\"))\n",
    "#     plot_features(X_train.loc[fours[i]].dropna().to_numpy(dtype=\"float32\"))\n",
    "# # plot_features(X_train.loc[0].dropna().to_numpy(dtype=\"float32\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_trimmed_0 = X_train.loc[0,].dropna().to_numpy(dtype=\"float32\")\n",
    "# # print(\"Training data shape: \", X_train.loc[0].dropna().to_numpy(dtype=\"float32\").shape)\n",
    "# x = np.linspace(0,X_train_trimmed_0.shape[0],X_train_trimmed_0.shape[0])\n",
    "# plt.plot(x, X_train_trimmed_0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Wavelet transform:\n",
    "### Create CWT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widths = np.arange(1,31)\n",
    "# print(\"cwtmatrix shape (30 from width x # signal length\")\n",
    "# Class = 3\n",
    "# for i in range(len(threes)):\n",
    "#         print(i)\n",
    "#         # print(len(X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\")))\n",
    "#         cwtmatr = signal.cwt(X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\"), signal.ricker, widths)\n",
    "#         # print(cwtmatr.shape)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(cwtmatr, extent=[-1, 1, 31, 1], cmap='PRGn', aspect='auto',\n",
    "#                 vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())\n",
    "#         plt.axis('off')\n",
    "#         # plt.show()\n",
    "#         plt.savefig(\"3/cwtmatr_class{}_index{}.png\".format(Class, i), bbox_inches='tight', pad_inches=0)\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 334\n",
    "IMG_HEIGHT = 217\n",
    "def load_image(img, training):\n",
    "    '''Helper Function to load the image'''\n",
    "    img = tf.image.decode_png(tf.io.read_file(img), channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = img / 127.5 - 1\n",
    "    img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    if training:\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = load_image(\"3/cwtmatr_class3_index0.png\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for imbalanced dataset:\n",
    " Idea for imbalanced data: sample all classes to be of size 170 and proceed using ensemble method of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper NN Structure:\n",
    "Automatic ECG Classification Using Continuous Wavelet\n",
    "Transform and Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Paper NN structure](Paper_pipeline.png \"Paper NN Structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- insert image -->\n",
    "![Paper NN structure](Paper_NN_structure.png \"Paper NN Structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor_model():\n",
    "    '''Create feature extractor'''\n",
    "    #determine input shape\n",
    "    model = keras.Sequential([\n",
    "        tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        tf.keras.layers.Conv2D(filters=16,kernel_size=7,strides=1,input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPool2D(5,5),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(32,3,1),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPool2D(3,3),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64,3,1),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPool2D(3),\n",
    "    ])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 211, 328, 16)      2368      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 211, 328, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 211, 328, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 42, 65, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 40, 63, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 40, 63, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 40, 63, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 13, 21, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 11, 19, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 11, 19, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 11, 19, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 3, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,952\n",
      "Trainable params: 25,728\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_feature_extractor_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: \n",
    "- Extract features from heartbeat templates and concatenate with scalar output from model\n",
    "- consider imbalanced dataset => add bias towards under-represented classes\n",
    "- train model\n",
    "- predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
