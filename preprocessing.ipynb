{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from biosppy.signals import ecg\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Data - may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import X_train.csv dataset into a pandas dataframe\n",
    "X_train = pd.read_csv(\"X_train.csv\", index_col=\"id\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", index_col=\"id\")\n",
    "X_test = pd.read_csv(\"X_test.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the class representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = y_train.to_numpy()\n",
    "ones = np.where(y_train_np == 0)[0]\n",
    "twos = np.where(y_train_np == 1)[0]\n",
    "threes = np.where(y_train_np == 2)[0]\n",
    "fours = np.where(y_train_np == 3)[0]\n",
    "np.savetxt(\"class_reps/ones.csv\", ones, delimiter=\",\", fmt=\"%d\")\n",
    "np.savetxt(\"class_reps/twos.csv\", twos, delimiter=\",\", fmt=\"%d\")\n",
    "np.savetxt(\"class_reps/threes.csv\", threes, delimiter=\",\", fmt=\"%d\")\n",
    "np.savetxt(\"class_reps/fours.csv\", fours, delimiter=\",\", fmt=\"%d\")\n",
    "print(len(ones))\n",
    "print(len(twos))\n",
    "print(len(threes))\n",
    "print(len(fours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Wavelet Transform â€“ create images and save them\n",
    "have to manually change the class number 3 times here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = np.arange(1,31)\n",
    "print(\"cwtmatrix shape (30 from width x # signal length\")\n",
    "Class = 3\n",
    "for i in range(len(threes)):\n",
    "        print(i)\n",
    "        # print(len(X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\")))\n",
    "        cwtmatr = signal.cwt(X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\"), signal.ricker, widths)\n",
    "        # print(cwtmatr.shape)\n",
    "        plt.figure()\n",
    "        plt.imshow(cwtmatr, extent=[-1, 1, 31, 1], cmap='PRGn', aspect='auto',\n",
    "                vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())\n",
    "        plt.axis('off')\n",
    "        # plt.show()\n",
    "        plt.savefig(\"cwt_images/3/cwtmatr_class{}_index{}.png\".format(Class, i), bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of additional features to extract from the signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_output = ecg.ecg(X_train.loc[ones[0]].dropna().to_numpy(dtype=\"float32\"))\n",
    "print(\"classes: \", ecg_output[0].keys())\n",
    "print(\"shape of time series: \", ecg_output[0][0].shape)\n",
    "print(\"shape of filtered series: \", ecg_output[0][1].shape)\n",
    "print(\"number of peaks\", ecg_output[0][2].shape[0])\n",
    "print(\"shape of templates: \", ecg_output[0][3].shape)\n",
    "print(\"peaks: \", ecg_output[0][2]/300)\n",
    "print(\"templates: \", ecg_output[0][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Heartbeats for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(signal):\n",
    "    r_peaks = ecg.engzee_segmenter(signal, 300)['rpeaks']\n",
    "    if len(r_peaks) >= 2:\n",
    "        beats = ecg.extract_heartbeats(signal, r_peaks, 300)['templates']\n",
    "        # print(\"Beats (peaks - 1, 180 proposals of heartbeats): \", beats)\n",
    "        if len(beats) != 0:\n",
    "            mu = np.mean(beats, axis=0) \n",
    "            var = np.std(beats, axis=0)\n",
    "            md = np.median(beats, axis=0)\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.subplot(211)\n",
    "\n",
    "            ax1 = plt.subplot(211)\n",
    "            ax1.plot(beats[0,:])\n",
    "            ax1.plot(beats[1,:])\n",
    "            ax1.plot(beats[2,:])\n",
    "            ax1.plot(beats[3,:])\n",
    "            ax1.set_title(\"template samples\")\n",
    "\n",
    "            ax2 = plt.subplot(212)\n",
    "            ax2.set_title(\"average template\")\n",
    "            ax2.plot(range(mu.shape[0]), mu, label='Average HeartBeat')\n",
    "            # Fill the variance range\n",
    "            ax2.fill_between(range(mu.shape[0]), mu - var, mu + var, linewidth=0, alpha=0.1)\n",
    "            # Plot a median\n",
    "            ax2.plot(range(md.shape[0]), md,  label='Median HeartBeat', color='#CC4F1B')\n",
    "    # ecg_results = ecg.ecg(signal, sampling_rate=300, show=True)\n",
    "    # return ecg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Peaks and store as concatenated matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_peaks = 159\n",
    "peaks = np.zeros((max_num_peaks, threes.shape[0]))\n",
    "for i in range(threes.shape[0]):\n",
    "    data = X_train.loc[threes[i]].dropna().to_numpy(dtype=\"float32\")\n",
    "    ECG = ecg.ecg(data, sampling_rate=300, show=False)\n",
    "    ecg_dimension = ECG[2].shape[0]\n",
    "    buffer = np.zeros((max_num_peaks - ecg_dimension))\n",
    "    peaks[:,i] = np.concatenate((ECG[2], buffer), axis=0)\n",
    "np.savetxt(\"peaks/3/ecg_peaks.csv\", peaks, delimiter=\",\", fmt='%0.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = pd.read_csv(\"peaks/4/ecg_peaks.csv\", header=None).to_numpy(dtype=\"float32\")\n",
    "zeros = np.where(peaks == 0)\n",
    "mean = np.mean(peaks, axis=0)\n",
    "std = np.std(peaks, axis=0)\n",
    "peaks_normalized = (peaks - mean) / std\n",
    "np.savetxt(\"peaks/4/ecg_peaks_normalized.csv\", peaks_normalized, delimiter=\",\", fmt='%0.7f')\n",
    "peaks_normalized[zeros] = 0\n",
    "np.savetxt(\"peaks/4/ecg_peaks_normalized_zeros.csv\", peaks_normalized, delimiter=\",\", fmt='%0.7f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
